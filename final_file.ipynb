{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define the data as a Pandas DataFrame\n",
    "data = {\n",
    "    'id': [1, 2],\n",
    "\n",
    "    'product_des': [\n",
    "        [\n",
    "        {'unit': 'origin', 'value': 32, 'dimentionality': 1},\n",
    "        {'unit': 'inches', 'value': 452, 'dimentionality': 2}\n",
    "    \n",
    "        \n",
    "    ],\n",
    "    [\n",
    "        {'unit': 'ounches', 'value': 32, 'dimentionality': 1},\n",
    "        {'unit': 'inches', 'value': 452, 'dimentionality': 2} \n",
    "    ]\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the schema using PyArrow\n",
    "schema = pa.schema([\n",
    "    pa.field('id', pa.int64()),\n",
    "    pa.field('product_des', pa.list_(pa.struct([\n",
    "        pa.field('unit', pa.string()),\n",
    "        pa.field('value', pa.int64()),\n",
    "        pa.field('dimentionality', pa.int64())\n",
    "        ])))\n",
    "\n",
    "  \n",
    "])\n",
    "\n",
    "# Convert the Pandas DataFrame to PyArrow Table\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n",
    "\n",
    "# Write the PyArrow Table to Parquet file\n",
    "# with pq.ParquetWriter(r'C:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1', schema) as writer:\n",
    "#     writer.write_table(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table, r\"C:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\exam.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('exam.parquet')\n",
    "\n",
    "# Convert the table to a Pandas DataFrame\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                        product_des\n",
      "0   1  [{'unit': 'origin', 'value': 32, 'dimentionali...\n",
      "1   2  [{'unit': 'ounches', 'value': 32, 'dimentional...\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'pyarrow.lib.StructType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 22\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m desc \u001b[39min\u001b[39;00m product_des:\n\u001b[0;32m     17\u001b[0m         struct_type \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mstruct([\n\u001b[0;32m     18\u001b[0m             pa\u001b[39m.\u001b[39mfield(\u001b[39m'\u001b[39m\u001b[39munit\u001b[39m\u001b[39m'\u001b[39m, pa\u001b[39m.\u001b[39mstring()),\n\u001b[0;32m     19\u001b[0m             pa\u001b[39m.\u001b[39mfield(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, pa\u001b[39m.\u001b[39mint64()),\n\u001b[0;32m     20\u001b[0m             pa\u001b[39m.\u001b[39mfield(\u001b[39m'\u001b[39m\u001b[39mdimentionality\u001b[39m\u001b[39m'\u001b[39m, pa\u001b[39m.\u001b[39mint64())\n\u001b[0;32m     21\u001b[0m         ])\n\u001b[1;32m---> 22\u001b[0m         struct_list\u001b[39m.\u001b[39mappend(struct_type(\n\u001b[0;32m     23\u001b[0m             desc[\u001b[39m'\u001b[39;49m\u001b[39munit\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     24\u001b[0m             desc[\u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     25\u001b[0m             desc[\u001b[39m'\u001b[39;49m\u001b[39mdimentionality\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     26\u001b[0m         ))\n\u001b[0;32m     27\u001b[0m     structs\u001b[39m.\u001b[39mappend(pa\u001b[39m.\u001b[39marray(struct_list))\n\u001b[0;32m     29\u001b[0m \u001b[39m# Create the PyArrow schema and table\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'pyarrow.lib.StructType' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "# Define some example data\n",
    "data = [\n",
    "    {'id': 1, 'product_des': [{'unit': 'origin', 'value': 32, 'dimentionality': 1}, {'unit': 'inches', 'value': 452, 'dimentionality': 2}]},\n",
    "    {'id': 2, 'product_des': [{'unit': 'ounces', 'value': 32, 'dimentionality': 1}, {'unit': 'inches', 'value': 452, 'dimentionality': 2}, {'unit': 'cm', 'value': 10, 'dimentionality': 1}]},\n",
    "    {'id': 3, 'product_des': [{'unit': 'meters', 'value': 2, 'dimentionality': 1}, {'unit': 'pounds', 'value': 5, 'dimentionality': 1}, {'unit': 'inches', 'value': 100, 'dimentionality': 2}, {'unit': 'cm', 'value': 20, 'dimentionality': 1}]},\n",
    "]\n",
    "\n",
    "# Create a list of structs for each row\n",
    "structs = []\n",
    "for row in data:\n",
    "    product_des = row['product_des']\n",
    "    struct_list = []\n",
    "    for desc in product_des:\n",
    "        struct_type = pa.struct([\n",
    "            pa.field('unit', pa.string()),\n",
    "            pa.field('value', pa.int64()),\n",
    "            pa.field('dimentionality', pa.int64())\n",
    "        ])\n",
    "        struct_list.append(struct_type(\n",
    "            desc['unit'],\n",
    "            desc['value'],\n",
    "            desc['dimentionality']\n",
    "        ))\n",
    "    structs.append(pa.array(struct_list))\n",
    "\n",
    "# Create the PyArrow schema and table\n",
    "schema = pa.schema([\n",
    "    pa.field('id', pa.int64()),\n",
    "    pa.field('product_des', pa.list_(pa.struct([\n",
    "        pa.field('unit', pa.string()),\n",
    "        pa.field('value', pa.int64()),\n",
    "        pa.field('dimentionality', pa.int64())\n",
    "    ])))\n",
    "])\n",
    "table = pa.Table.from_arrays([\n",
    "    pa.array([row['id'] for row in data]),\n",
    "    pa.list_(structs)\n",
    "], schema=schema)\n",
    "\n",
    "# Write the table to a Parquet file\n",
    "pq.write_table(table, 'product_descriptions.parquet')\n",
    "\n",
    "# Read the table back from the Parquet file\n",
    "table = pq.read_table('product_descriptions.parquet')\n",
    "\n",
    "# Convert the PyArrow table to a Pandas DataFrame\n",
    "df = table.to_pandas()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 1\n",
      "index: 2\n",
      "index: 3\n",
      "index: 4\n",
      "index: 5\n",
      "index: 6\n",
      "index: 7\n",
      "index: 8\n",
      "index: 9\n",
      "{'id': ['078c02969df534dd252ead140ff1e2e2', '5daf53900ecea17db9d855cde97819de', '2f0ee547ae16a9e3ca19e7ba1d1f14e9', 'c74918fa58c77ef27a96e3badd8e7566', '6c234fb210cc667034e1161cba15d8c5', '759d9dd6bc1ac62995bd69db5b626bfd', 'd75a82375ca598bd148cd5061006054c', 'f3d5db1b08f5fb394ff73834238e9e69', 'acc54e85b1677734e5085a34e4b4b0c7', '845b7af056e19a8eb729d907e43a9b42'], 'product_des': [[{'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'inches', 'value': 140.0, 'dimentionality': 3}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'origin', 'value': 5, 'dimentionality': 1}, {'unit': 'quantity', 'value': 6, 'dimentionality': 1}], [{'unit': 'inches', 'value': 140.0, 'dimentionality': 3}, {'unit': 'ounces', 'value': '7.2', 'dimentionality': 1}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'origin', 'value': 5, 'dimentionality': 1}, {'unit': 'quantity', 'value': 6, 'dimentionality': 1}], [{'unit': 'inches', 'value': 32.0, 'dimentionality': 3}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'inches', 'value': 900.0, 'dimentionality': 3}, {'unit': 'pounds', 'value': '4', 'dimentionality': 1}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'inches', 'value': 68.58547200000001, 'dimentionality': 3}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'lb', 'value': '7.7', 'dimentionality': 1}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}], [{'unit': 'inches', 'value': 251.32952999999998, 'dimentionality': 3}, {'unit': 'pounds', 'value': '1.38', 'dimentionality': 1}, {'unit': 'origin', 'value': 5, 'dimentionality': 1}, {'unit': 'quantity', 'value': 6, 'dimentionality': 1}]]}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from country_call import find_country\n",
    "import pandas as pd\n",
    "import re\n",
    "from material_selection import find_materials\n",
    "df = pd.read_parquet('product_attrs.parquet.gzip')\n",
    "df1 = pd.DataFrame(columns=['Product_id', 'Origin', 'Material','inches','inches_dimension','Pounds','Ounces','Lb','Quantity'])\n",
    "data=[]\n",
    "id = []\n",
    "product_des=[]\n",
    "for index, row in df.head(10).iterrows():\n",
    "    print(f\"index: {index}\")\n",
    "    dimention_1=\"\"\n",
    "    dimention_2=\"\"\n",
    "    dimention_3=\"\"\n",
    "    dimention_4=\"\"\n",
    "    dimention_5=\"\"\n",
    "    inches=\"\"\n",
    "    pounds=\"\"\n",
    "    ounces=\"\"\n",
    "    lb=\"\"\n",
    "    product_id=\"\"\n",
    "    country=\"\"\n",
    "    material=[]\n",
    "    quantity=\"\"\n",
    "    data=[]\n",
    "    \n",
    "    # Finding Dimention 1\n",
    "    product_id=row[1]\n",
    "    id.append(product_id)\n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split(\" \")[-1]\n",
    "        if dimention_unit==\"inches\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_1=(len(numbers))\n",
    "            inches = 1\n",
    "            for num in numbers:\n",
    "                inches *= float(num)\n",
    "            diction={'unit':'inches','value':inches,'dimentionality':dimention_1}\n",
    "            data.append(diction)    \n",
    "                \n",
    "     # Finding Dimention 2               \n",
    "    if row[3]!=None:\n",
    "        dimention_unit=row[3].split(\" \")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"pounds\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[3])\n",
    "            dimention_2=1\n",
    "            pounds=numbers[0]\n",
    "            diction={'unit':'pounds','value':pounds,'dimentionality':1}\n",
    "            data.append(diction)\n",
    "            \n",
    "            \n",
    "    # Finding Dimention 3            \n",
    "\n",
    "    if row[3]!=None:\n",
    "        dimention_unit=row[3].split(\" \")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"ounces\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[3])\n",
    "            dimention_3=1\n",
    "            ounces=numbers[0]\n",
    "            diction={'unit':'ounces','value':ounces,'dimentionality':1}\n",
    "            data.append(diction)\n",
    "\n",
    "            \n",
    "    # Finding Dimention 4\n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split(\"l\")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"b\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_4=1\n",
    "            lb=numbers[0]\n",
    "            diction={'unit':'lb','value':lb,'dimentionality':1}\n",
    "            data.append(diction)\n",
    "\n",
    "                \n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split('\"')[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"h\" or dimention_unit==\"w\" or dimention_unit==\"l\" or dimention_unit==\"d\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_1=(len(numbers))\n",
    "            inches = 1\n",
    "            for num in numbers:\n",
    "                inches *= float(num)\n",
    "            # print(inches)\n",
    "            # print(dimention_5)\n",
    "            diction={'unit':'inches','value':inches,'dimentionality':dimention_1}\n",
    "            data.append(diction)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "    title=f\"Index: {index}, Row data: {row[4]}\"\n",
    "    descrip=f\"Index: {index}, Row data: {row[5]}\"\n",
    "    country=find_country(title)\n",
    "    if country == None:\n",
    "        country = find_country(descrip)\n",
    "        diction={'unit':'origin','value':5,'dimentionality':1}\n",
    "        data.append(diction)\n",
    "    # print(country)\n",
    "    material=find_materials(title)\n",
    "    if material == None:\n",
    "        material = find_materials(descrip)\n",
    "        diction={'unit':'materials','value':8,'dimentionality':1}\n",
    "        data.append(diction)   \n",
    "    \n",
    "    # Use regular expressions to find the quantity information\n",
    "    text=f\"{title} {descrip}\"\n",
    "    match = re.search(r\"(pack of|pk|pcs|pieces|set|qty|piece|set of|piece of)\\s?(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"(\\d+)(\\s?|\\s*)(pack|pk|pcs|pieces|set|packs|sets|piece|Pair Pack|Pair Packs|Count|Counts)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"numeric_(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"(\\d+)\\s*-\\s*(pk|pcs|pieces|set|piece|pack|packs|Pair Pack|Pair Packs|Count|Counts)\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        quantity = match.group()\n",
    "        diction={'unit':'quantity','value':6,'dimentionality':1}\n",
    "        data.append(diction)\n",
    "    product_des.append(data)\n",
    "main_data={\n",
    "    'id':id,\n",
    "    'product_des':product_des    \n",
    "}\n",
    "        # print(\"Quantity:\", quantity)\n",
    "    # else:\n",
    "        # print(\"Quantity not found.\")\n",
    "\n",
    "    # data = {'Product_id':product_id, 'Origin':country, 'Material':str(material),'inches':inches,'inches_dimension':dimention_1,'Pounds':pounds,'Ounces':ounces,'Lb':lb,'Quantity':quantity}\n",
    "    # df1 = df1.append(data, ignore_index=True)\n",
    "    \n",
    "# Create a list of structs for each row\n",
    "print(main_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "(\"Expected bytes, got a 'int' object\", 'Conversion failed for column product_des with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 16\u001b[0m\n\u001b[0;32m      4\u001b[0m schema \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mschema([\n\u001b[0;32m      5\u001b[0m     pa\u001b[39m.\u001b[39mfield(\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, pa\u001b[39m.\u001b[39mstring()),\n\u001b[0;32m      6\u001b[0m     pa\u001b[39m.\u001b[39mfield(\u001b[39m'\u001b[39m\u001b[39mproduct_des\u001b[39m\u001b[39m'\u001b[39m, pa\u001b[39m.\u001b[39mlist_(pa\u001b[39m.\u001b[39mstruct([\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m   \n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     15\u001b[0m \u001b[39m# Convert the Pandas DataFrame to PyArrow Table\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m table \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(df, schema\u001b[39m=\u001b[39;49mschema)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\table.pxi:3681\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[0;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[0;32m    612\u001b[0m               \u001b[39mfor\u001b[39;49;00m c, f \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(columns_to_convert, convert_fields)]\n\u001b[0;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[0;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[0;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[0;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[0;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m field_nullable \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mnull_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mField \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was non-nullable but pandas column \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    601\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mhad \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m null values\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(field),\n\u001b[0;32m    602\u001b[0m                                                  result\u001b[39m.\u001b[39mnull_count))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(col, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49mtype_, from_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, safe\u001b[39m=\u001b[39;49msafe)\n\u001b[0;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:323\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pyarrow\\error.pxi:123\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowTypeError\u001b[0m: (\"Expected bytes, got a 'int' object\", 'Conversion failed for column product_des with type object')"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(main_data)\n",
    "\n",
    "# Define the schema using PyArrow\n",
    "schema = pa.schema([\n",
    "    pa.field('id', pa.string()),\n",
    "    pa.field('product_des', pa.list_(pa.struct([\n",
    "        pa.field('unit', pa.string()),\n",
    "        pa.field('value', pa.string()),\n",
    "        pa.field('dimentionality', pa.string())\n",
    "        ])))\n",
    "\n",
    "  \n",
    "])\n",
    "\n",
    "# Convert the Pandas DataFrame to PyArrow Table\n",
    "table = pa.Table.from_pandas(df, schema=schema)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
