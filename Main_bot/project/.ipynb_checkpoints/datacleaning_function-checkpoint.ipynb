{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db5ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from country_call import find_country\n",
    "import pandas as pd\n",
    "import re\n",
    "from material_selection import find_materials\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50ac111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('product_attrs.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b916e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(row):\n",
    "\n",
    "#     for index, row in df.head(10).iterrows():\n",
    "#     print(f\"index: {index}\")\n",
    "    dimention_1=\"\"\n",
    "    dimention_2=\"\"\n",
    "    dimention_3=\"\"\n",
    "    dimention_4=\"\"\n",
    "    dimention_5=\"\"\n",
    "    inches=\"\"\n",
    "    pounds=\"\"\n",
    "    ounces=\"\"\n",
    "    lb=\"\"\n",
    "    product_id=\"\"\n",
    "    country=\"\"\n",
    "    material=[]\n",
    "    quantity=\"\"\n",
    "    data=[]\n",
    "    # idd = []\n",
    "    # Finding Dimention 1\n",
    "    product_id=row[1]\n",
    "    idd=(product_id)\n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split(\" \")[-1]\n",
    "        if dimention_unit==\"inches\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_1=(len(numbers))\n",
    "            inches = 1\n",
    "            for num in numbers:\n",
    "                inches *= float(num)\n",
    "            diction={'unit':'inches','value':str(inches),'dimentionality':dimention_1}\n",
    "            data.append(diction)   \n",
    "\n",
    "     # Finding Dimention 2               \n",
    "    if row[3]!=None:\n",
    "        dimention_unit=row[3].split(\" \")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"pounds\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[3])\n",
    "            dimention_2=1\n",
    "            pounds=numbers[0]\n",
    "            diction={'unit':'pounds','value':str(pounds),'dimentionality':1}\n",
    "            data.append(diction)\n",
    "\n",
    "\n",
    "    # Finding Dimention 3            \n",
    "\n",
    "    if row[3]!=None:\n",
    "        dimention_unit=row[3].split(\" \")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"ounces\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[3])\n",
    "            dimention_3=1\n",
    "            ounces=numbers[0]\n",
    "            diction={'unit':'ounces','value':str(ounces),'dimentionality':1}\n",
    "            data.append(diction)\n",
    "\n",
    "\n",
    "    # Finding Dimention 4\n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split(\"l\")[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"b\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_4=1\n",
    "            lb=numbers[0]\n",
    "            diction={'unit':'lb','value':str(lb),'dimentionality':1}\n",
    "            data.append(diction)\n",
    "\n",
    "\n",
    "    if row[2]!=None:\n",
    "        dimention_unit=row[2].split('\"')[-1]\n",
    "        dimention_unit=dimention_unit.lower()\n",
    "        if dimention_unit==\"h\" or dimention_unit==\"w\" or dimention_unit==\"l\" or dimention_unit==\"d\":\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', row[2])\n",
    "            dimention_1=(len(numbers))\n",
    "            inches = 1\n",
    "            for num in numbers:\n",
    "                inches *= float(num)\n",
    "            # print(inches)\n",
    "            # print(dimention_5)\n",
    "            diction={'unit':'inches','value':str(inches),'dimentionality':dimention_1}\n",
    "            data.append(diction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    title=f\"Index: {index}, Row data: {row[4]}\"\n",
    "    descrip=f\"Index: {index}, Row data: {row[5]}\"\n",
    "    country=find_country(title)\n",
    "    if country == None:\n",
    "        country = find_country(descrip)\n",
    "        if country!=None:\n",
    "            diction={'unit':'Origin','value':country,'dimentionality':1}\n",
    "            data.append(diction)\n",
    "    # print(country)\n",
    "    material=find_materials(title)\n",
    "    if material == None:\n",
    "        material = find_materials(descrip)\n",
    "        diction={'unit':'materials','value':material,'dimentionality':1}\n",
    "        data.append(diction)  \n",
    "\n",
    "    # Use regular expressions to find the quantity information\n",
    "    text=f\"{title} {descrip}\"\n",
    "    match = re.search(r\"(pack of|pk|pcs|pieces|set|qty|piece|set of|piece of)\\s?(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"(\\d+)(\\s?|\\s*)(pack|pk|pcs|pieces|set|packs|sets|piece|Pair Pack|Pair Packs|Count|Counts)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"numeric_(\\d+)\", text, flags=re.IGNORECASE)\n",
    "    if match==None:\n",
    "        match = re.search(r\"(\\d+)\\s*-\\s*(pk|pcs|pieces|set|piece|pack|packs|Pair Pack|Pair Packs|Count|Counts)\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        quantity = match.group()\n",
    "        diction={'unit':'Quantity','value':str(quantity),'dimentionality':1}\n",
    "        data.append(diction)\n",
    "#         product_des.append(data)\n",
    "#     main_data={\n",
    "#         'id':idd,\n",
    "#         'product_des':product_des    \n",
    "#     }\n",
    "    return idd,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e89838a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"output.parquet\"\n",
    "existing_dataset = pq.ParquetDataset(dataset_path).read().to_pandas()\n",
    "for index, row in df.head(900).iterrows():\n",
    "    x,y=data_clean(row)\n",
    "    new_row = {'id': x, 'product_des': y}\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    existing_dataset = pd.concat([existing_dataset, new_row_df], ignore_index=True)\n",
    "    deduplicated_data = existing_dataset.drop_duplicates(subset='id')\n",
    "    table = pa.Table.from_pandas(deduplicated_data, schema=schema)\n",
    "    # Specify the output file path\n",
    "    output_file = \"output.parquet\"\n",
    "\n",
    "    # Save the PyArrow table to Parquet format\n",
    "    pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b8ff253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_data = existing_dataset.drop_duplicates(subset='id')\n",
    "table = pa.Table.from_pandas(deduplicated_data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a81a6904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    id   \n",
      "0     078c02969df534dd252ead140ff1e2e2  \\\n",
      "1     5daf53900ecea17db9d855cde97819de   \n",
      "2     2f0ee547ae16a9e3ca19e7ba1d1f14e9   \n",
      "3     c74918fa58c77ef27a96e3badd8e7566   \n",
      "4     6c234fb210cc667034e1161cba15d8c5   \n",
      "...                                ...   \n",
      "2296  e76f8c7c0c826f1f51a059bd3a285111   \n",
      "2297  5c877b617a9883ba337a77b7cb45cbfd   \n",
      "2298  550fb64af4b22573d7837448fa77a478   \n",
      "2299  d83b1961b6cc182a5dd15291dc2f1a2d   \n",
      "2300  93012ab9de079d153b540d541b909324   \n",
      "\n",
      "                                            product_des  \n",
      "0                                                    []  \n",
      "1     [{'unit': 'inches', 'value': '140.0', 'dimenti...  \n",
      "2     [{'unit': 'Quantity', 'value': 'Pack of 4', 'd...  \n",
      "3     [{'unit': 'inches', 'value': '140.0', 'dimenti...  \n",
      "4     [{'unit': 'Origin', 'value': 'United States', ...  \n",
      "...                                                 ...  \n",
      "2296  [{'unit': 'Origin', 'value': 'United States', ...  \n",
      "2297  [{'unit': 'inches', 'value': '973.560000000000...  \n",
      "2298  [{'unit': 'inches', 'value': '27.966', 'diment...  \n",
      "2299                                                 []  \n",
      "2300  [{'unit': 'inches', 'value': '8.64', 'dimentio...  \n",
      "\n",
      "[901 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(deduplicated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee05b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(main_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c1dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = pa.schema([\n",
    "    pa.field('id', pa.string()),\n",
    "    pa.field('product_des', pa.list_(pa.struct([\n",
    "        pa.field('unit', pa.string()),\n",
    "        pa.field('value', pa.string()),\n",
    "        pa.field('dimentionality', pa.int64())\n",
    "        ])))\n",
    "\n",
    "  \n",
    "])\n",
    "\n",
    "# Convert the Pandas DataFrame to PyArrow Table\n",
    "table = pa.Table.from_pandas(df1, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86832397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the output file path\n",
    "output_file = \"output.parquet\"\n",
    "\n",
    "# Save the PyArrow table to Parquet format\n",
    "pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e89b9b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'dict'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.parquet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m existing_dataset \u001b[39m=\u001b[39m pq\u001b[39m.\u001b[39mParquetDataset(dataset_path)\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mto_pandas()\n\u001b[1;32m----> 5\u001b[0m combined_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([existing_dataset, x])\n\u001b[0;32m      7\u001b[0m deduplicated_data \u001b[39m=\u001b[39m combined_data\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m table \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(deduplicated_data, schema\u001b[39m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:462\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    458\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         )\n\u001b[1;32m--> 462\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    464\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[0;32m    466\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'dict'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Specify the existing Parquet dataset path\n",
    "dataset_path = \"output.parquet\"\n",
    "\n",
    "existing_dataset = pq.ParquetDataset(dataset_path).read().to_pandas()\n",
    "combined_data = pd.concat([existing_dataset, df1])\n",
    "\n",
    "deduplicated_data = combined_data.drop_duplicates(subset='id')\n",
    "table = pa.Table.from_pandas(deduplicated_data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bd51624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31cc0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([existing_dataset, df1])\n",
    "# print(existing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "335f444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"output.parquet\"\n",
    "\n",
    "existing_dataset = pq.ParquetDataset(dataset_path).read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "15dcdc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_des</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>078c02969df534dd252ead140ff1e2e2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5daf53900ecea17db9d855cde97819de</td>\n",
       "      <td>[{'unit': 'inches', 'value': '140.0', 'dimenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2f0ee547ae16a9e3ca19e7ba1d1f14e9</td>\n",
       "      <td>[{'unit': 'Quantity', 'value': 'Pack of 4', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c74918fa58c77ef27a96e3badd8e7566</td>\n",
       "      <td>[{'unit': 'inches', 'value': '140.0', 'dimenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6c234fb210cc667034e1161cba15d8c5</td>\n",
       "      <td>[{'unit': 'Origin', 'value': 'United States', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>9cacbfc5e9f53bccb7612db79d323ebf</td>\n",
       "      <td>[{'unit': 'inches', 'value': '21.3059999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>42d4fb160439f8fcb2c508171dfbc9e2</td>\n",
       "      <td>[{'unit': 'inches', 'value': '80.2444499999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>83c6e5236db8ab55bdc6ea3ffeec5737</td>\n",
       "      <td>[{'unit': 'inches', 'value': '93.7649999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>52bc8acdfdc749d2407fd6d84dcf4cee</td>\n",
       "      <td>[{'unit': 'inches', 'value': '13.414632', 'dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>f3ca5350435ecbef197932981f0e7cac</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id   \n",
       "0     078c02969df534dd252ead140ff1e2e2  \\\n",
       "1     5daf53900ecea17db9d855cde97819de   \n",
       "2     2f0ee547ae16a9e3ca19e7ba1d1f14e9   \n",
       "3     c74918fa58c77ef27a96e3badd8e7566   \n",
       "4     6c234fb210cc667034e1161cba15d8c5   \n",
       "...                                ...   \n",
       "996   9cacbfc5e9f53bccb7612db79d323ebf   \n",
       "997   42d4fb160439f8fcb2c508171dfbc9e2   \n",
       "998   83c6e5236db8ab55bdc6ea3ffeec5737   \n",
       "999   52bc8acdfdc749d2407fd6d84dcf4cee   \n",
       "1000  f3ca5350435ecbef197932981f0e7cac   \n",
       "\n",
       "                                            product_des  \n",
       "0                                                    []  \n",
       "1     [{'unit': 'inches', 'value': '140.0', 'dimenti...  \n",
       "2     [{'unit': 'Quantity', 'value': 'Pack of 4', 'd...  \n",
       "3     [{'unit': 'inches', 'value': '140.0', 'dimenti...  \n",
       "4     [{'unit': 'Origin', 'value': 'United States', ...  \n",
       "...                                                 ...  \n",
       "996   [{'unit': 'inches', 'value': '21.3059999999999...  \n",
       "997   [{'unit': 'inches', 'value': '80.2444499999999...  \n",
       "998   [{'unit': 'inches', 'value': '93.7649999999999...  \n",
       "999   [{'unit': 'inches', 'value': '13.414632', 'dim...  \n",
       "1000                                                 []  \n",
       "\n",
       "[1001 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec8781c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snowflake'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProgrammingError\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'snowflake'"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "from snowflake.connector.errors import ProgrammingError\n",
    "import os\n",
    "import json\n",
    "# from utils.get_aws_secrets import get_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503ada9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyodbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyodbc\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyodbc'"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils.get_aws_secrets import get_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358a9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "account = 'wkb13332'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'ANALYTICS'\n",
    "schema = 'AMAZON'\n",
    "table = 'amazon_attributes'\n",
    "user = 'pxkazi'\n",
    "password = 'Ahmedrahat14'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9825d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_url = f'snowflake://{user}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b5c7383",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchModuleError",
     "evalue": "Can't load plugin: sqlalchemy.dialects:snowflake",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m engine \u001b[39m=\u001b[39m create_engine(connection_url)\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\sqlalchemy\\util\\deprecations.py:283\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    277\u001b[0m         _warn_with_version(\n\u001b[0;32m    278\u001b[0m             messages[m],\n\u001b[0;32m    279\u001b[0m             versions[m],\n\u001b[0;32m    280\u001b[0m             version_warnings[m],\n\u001b[0;32m    281\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m    282\u001b[0m         )\n\u001b[1;32m--> 283\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:552\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m u \u001b[39m=\u001b[39m _url\u001b[39m.\u001b[39mmake_url(url)\n\u001b[0;32m    550\u001b[0m u, plugins, kwargs \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[1;32m--> 552\u001b[0m entrypoint \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39;49m_get_entrypoint()\n\u001b[0;32m    553\u001b[0m _is_async \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_is_async\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    554\u001b[0m \u001b[39mif\u001b[39;00m _is_async:\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\sqlalchemy\\engine\\url.py:754\u001b[0m, in \u001b[0;36mURL._get_entrypoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrivername\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 754\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39;49mload(name)\n\u001b[0;32m    755\u001b[0m \u001b[39m# check for legacy dialects that\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[39m# would return a module with 'dialect' as the\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[39m# actual class\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    759\u001b[0m     \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdialect\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    760\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdialect, \u001b[39mtype\u001b[39m)\n\u001b[0;32m    761\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdialect, Dialect)\n\u001b[0;32m    762\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\User\\PycharmProjects\\pythonProject3\\Planet_X\\Phase_1\\Final\\env\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:368\u001b[0m, in \u001b[0;36mPluginLoader.load\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimpls[name] \u001b[39m=\u001b[39m impl\u001b[39m.\u001b[39mload\n\u001b[0;32m    366\u001b[0m         \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mload()\n\u001b[1;32m--> 368\u001b[0m \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mNoSuchModuleError(\n\u001b[0;32m    369\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load plugin: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup, name)\n\u001b[0;32m    370\u001b[0m )\n",
      "\u001b[1;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:snowflake"
     ]
    }
   ],
   "source": [
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dcd2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awscli\n",
      "  Downloading awscli-1.27.137-py3-none-any.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 249.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: botocore==1.29.137 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from awscli) (1.29.137)\n",
      "Collecting docutils<0.17,>=0.10\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "     ------------------------------------ 548.2/548.2 kB 136.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from awscli) (0.6.1)\n",
      "Collecting PyYAML<5.5,>=3.10\n",
      "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
      "     ------------------------------------ 175.1/175.1 kB 229.4 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting colorama<0.4.5,>=0.2.5\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting rsa<4.8,>=3.1.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from botocore==1.29.137->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from botocore==1.29.137->awscli) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from botocore==1.29.137->awscli) (1.26.15)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     -------------------------------------- 83.9/83.9 kB 214.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\pycharmprojects\\pythonproject3\\planet_x\\phase_1\\final\\env\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.29.137->awscli) (1.16.0)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (pyproject.toml): started\n",
      "  Building wheel for PyYAML (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp311-cp311-win_amd64.whl size=45670 sha256=eb42a3ffbcd35dfc054ca0cdaf63a7a77f225e0db0db8187e90917a5156337b1\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\13\\d5\\5b\\082ef0599cd0dde3d1f273ceebebe6cda67201058a70ade961\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, pyasn1, docutils, colorama, rsa, awscli\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "Successfully installed PyYAML-5.4.1 awscli-1.27.137 colorama-0.4.4 docutils-0.16 pyasn1-0.5.0 rsa-4.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
